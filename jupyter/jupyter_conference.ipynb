{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.microsoft.com/en-us/academic-services/graph/reference-data-schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "CONFERENCE_SERIES = \"mag/ConferenceSeries.txt\"\n",
    "CONFERENCE_SERIES_HEADER = [\n",
    "    \"ConferenceSeriesId\",\n",
    "    \"Rank\",\n",
    "    \"NormalizedName\",\n",
    "    \"DisplayName\",\n",
    "    \"PaperCount\",\n",
    "    \"CitationCount\",\n",
    "    \"CreatedDate\",\n",
    "]\n",
    "CONFERENCE_INSTANCES = \"mag/ConferenceInstances.txt\"\n",
    "CONFERENCE_INSTANCES_HEADER = [\n",
    "    \"ConferenceInstanceId\",\n",
    "    \"NormalizedName\",\n",
    "    \"DisplayName\",\n",
    "    \"ConferenceSeriesId\",\n",
    "    \"Location\",\n",
    "    \"OfficialUrl\",\n",
    "    \"StartDate\",\n",
    "    \"EndDate\",\n",
    "    \"AbstractRegistrationDate\",\n",
    "    \"SubmissionDeadlineDate\",\n",
    "    \"NotificationDueDate\",\n",
    "    \"FinalVersionDueDate\",\n",
    "    \"PageCount\",\n",
    "    \"CitationCount\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"CreatedDate\",\n",
    "]\n",
    "PAPERS = \"mag/Papers.txt\"\n",
    "PAPERS_HEADER = [\n",
    "    \"PaperId\",\n",
    "    \"Rank\",\n",
    "    \"Doi\",\n",
    "    \"DocType\",\n",
    "    \"PaperTitle\",\n",
    "    \"OriginalTitle\",\n",
    "    \"BookTitle\",\n",
    "    \"Year\",\n",
    "    \"Date\",\n",
    "    \"Publisher\",\n",
    "    \"JournalId\",\n",
    "    \"ConferenceSeriesId\",\n",
    "    \"ConferenceInstanceId\",\n",
    "    \"Volumne\",\n",
    "    \"Issue\",\n",
    "    \"FirstPage\",\n",
    "    \"LastPage\",\n",
    "    \"ReferenceCount\",\n",
    "    \"CitationCount\",\n",
    "    \"EstimatedCitation\",\n",
    "    \"OriginalVenue\",\n",
    "    \"FamilyId\",\n",
    "    \"CreatedDate\",\n",
    "]\n",
    "PAPER_AUTHOR_AFFILIATIONS = \"mag/PaperAuthorAffiliations.txt\"\n",
    "PAPER_AUTHOR_AFFILIATIONS_HEADER = [\n",
    "    \"PaperId\",\n",
    "    \"AuthorId\",\n",
    "    \"AffiliationId\",\n",
    "    \"AuthorSequenceNumber\",\n",
    "    \"OriginalAuthor\",\n",
    "    \"OritinalAffiliation\",\n",
    "]\n",
    "AUTHOR = \"mag/Authors.txt\"\n",
    "AUTHOR_HEADER = [\n",
    "    \"AuthorId\",\n",
    "    \"Rank\",\n",
    "    \"NormalizedName\",\n",
    "    \"DisplayName\",\n",
    "    \"LastKnownAffiliationId\",\n",
    "    \"PaperCount\",\n",
    "    \"CitationCount\",\n",
    "    \"CreateDate\",\n",
    "]\n",
    "PAPER_FIELDS_OF_STUDY = \"mag/PaperFieldsOfStudy.txt\"\n",
    "PAPER_FIELDS_OF_STUDY_HEADER = [\"PaperId\", \"FieldOfStudyId\", \"Score\"]\n",
    "FIELDS_OF_STUDY = \"mag/FieldsOfStudy.txt\"\n",
    "FIELDS_OF_STUDY_HEADER = [\n",
    "    \"FieldOfStudyId\",\n",
    "    \"Rank\",\n",
    "    \"NormalizedName\",\n",
    "    \"DisplayName\",\n",
    "    \"MainType\",\n",
    "    \"Level\",\n",
    "    \"PaperCount\",\n",
    "    \"CitationCount\",\n",
    "    \"CreateDate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conferences(interested_range, filename=None):\n",
    "    with open(CONFERENCE_SERIES) as fp:\n",
    "        conference_series_df = pd.read_csv(\n",
    "            fp, sep=\"\\t\", header=None, names=CONFERENCE_SERIES_HEADER\n",
    "        )\n",
    "\n",
    "    with open(CONFERENCE_INSTANCES) as fp:\n",
    "        conference_instances_df = pd.read_csv(\n",
    "            fp, sep=\"\\t\", header=None, names=CONFERENCE_INSTANCES_HEADER\n",
    "        )\n",
    "\n",
    "    kdd_series = conference_series_df[conference_series_df.NormalizedName == \"KDD\"]\n",
    "    kdd_instances = conference_instances_df[\n",
    "        (\n",
    "            conference_instances_df.ConferenceSeriesId\n",
    "            == kdd_series.ConferenceSeriesId.iloc[0]\n",
    "        )\n",
    "        & (conference_instances_df.DisplayName.isin(interested_range))\n",
    "    ]\n",
    "    if filename:\n",
    "        kdd_instances.to_csv(filename)\n",
    "    return kdd_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_papers(kdd_instances, num_loops=-1):\n",
    "    chunksize = 10 ** 6\n",
    "    count = 0\n",
    "    paperCounter = Counter({})\n",
    "    relevantPapers = pd.DataFrame(columns=PAPERS_HEADER)\n",
    "    for chunk in pd.read_csv(\n",
    "        PAPERS,\n",
    "        chunksize=chunksize,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=PAPERS_HEADER,\n",
    "        low_memory=False,\n",
    "    ):\n",
    "        count += 1\n",
    "        print(f\"Processing {chunksize * (count - 1)} - {chunksize * count}\")\n",
    "        paperCounter += Counter(\n",
    "            dict(\n",
    "                pd.to_numeric(chunk.Year, errors=\"coerce\")\n",
    "                .astype(\"Int32\")\n",
    "                .value_counts()\n",
    "            )\n",
    "        )\n",
    "        relevantPapers = relevantPapers.append(\n",
    "            chunk[\n",
    "                chunk.ConferenceInstanceId.isin(\n",
    "                    list(kdd_instances.ConferenceInstanceId)\n",
    "                )\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        if count == num_loops:\n",
    "            break\n",
    "    all_paper_count = (\n",
    "        pd.DataFrame.from_dict(paperCounter, orient=\"index\")\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"year\", 0: \"count\"})\n",
    "    )\n",
    "    all_paper_count.to_csv(r\"results/all_paper_count.csv\")\n",
    "    relevantPapers.to_csv(r\"results/kdd_papers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paper_author_affiliation(kdd_papers, num_loops=-1):\n",
    "    chunksize = 10 ** 7\n",
    "    count = 0\n",
    "    relavantPaperAuthorAffiliations = pd.DataFrame(\n",
    "        columns=PAPER_AUTHOR_AFFILIATIONS_HEADER\n",
    "    )\n",
    "    for chunk in pd.read_csv(\n",
    "        PAPER_AUTHOR_AFFILIATIONS,\n",
    "        chunksize=chunksize,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=PAPER_AUTHOR_AFFILIATIONS_HEADER,\n",
    "    ):\n",
    "        count += 1\n",
    "        print(f\"Processing {chunksize * (count - 1)} - {chunksize * count}\")\n",
    "        relavantPaperAuthorAffiliations = relavantPaperAuthorAffiliations.append(\n",
    "            chunk[chunk.PaperId.isin(list(kdd_papers.PaperId))], ignore_index=True\n",
    "        )\n",
    "        if count == num_loops:\n",
    "            break\n",
    "    relavantPaperAuthorAffiliations.to_csv(r\"results/kdd_paper_author_affiliations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_author(kdd_paper_author_affiliation, num_loops=-1):\n",
    "    chunksize = 10 ** 6\n",
    "    count = 0\n",
    "    relevantAuthors = pd.DataFrame(columns=AUTHOR_HEADER)\n",
    "    for chunk in pd.read_csv(\n",
    "        AUTHOR, chunksize=chunksize, sep=\"\\t\", header=None, names=AUTHOR_HEADER\n",
    "    ):\n",
    "        count += 1\n",
    "        print(f\"Processing {chunksize * (count - 1)} - {chunksize * count}\")\n",
    "        relevantAuthors = relevantAuthors.append(\n",
    "            chunk[chunk.AuthorId.isin(list(kdd_paper_author_affiliation.AuthorId))],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        if count == num_loops:\n",
    "            break\n",
    "    relevantAuthors.to_csv(r\"results/kdd_authors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paper_author_affiliation_for_authors(kdd_authors, num_loops=-1):\n",
    "    chunksize = 10 ** 7\n",
    "    count = 0\n",
    "    relavantPaperAuthorAffiliations = pd.DataFrame(\n",
    "        columns=PAPER_AUTHOR_AFFILIATIONS_HEADER\n",
    "    )\n",
    "    for chunk in pd.read_csv(\n",
    "        PAPER_AUTHOR_AFFILIATIONS,\n",
    "        chunksize=chunksize,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=PAPER_AUTHOR_AFFILIATIONS_HEADER,\n",
    "    ):\n",
    "        count += 1\n",
    "        print(f\"Processing {chunksize * (count - 1)} - {chunksize * count}\")\n",
    "        relavantPaperAuthorAffiliations = relavantPaperAuthorAffiliations.append(\n",
    "            chunk[chunk.AuthorId.isin(list(kdd_authors.AuthorId))], ignore_index=True\n",
    "        )\n",
    "        if count == num_loops:\n",
    "            break\n",
    "    relavantPaperAuthorAffiliations.to_csv(\n",
    "        r\"results/kdd_paper_author_affiliations_for_authors.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paper_fields_of_study(paper_list, num_loops=-1):\n",
    "    chunksize = 10 ** 7\n",
    "    count = 0\n",
    "    relevantPaperFieldsOfStudy = pd.DataFrame(columns=PAPER_FIELDS_OF_STUDY_HEADER)\n",
    "    for chunk in pd.read_csv(\n",
    "        PAPER_FIELDS_OF_STUDY,\n",
    "        chunksize=chunksize,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=PAPER_FIELDS_OF_STUDY_HEADER,\n",
    "    ):\n",
    "        count += 1\n",
    "        print(f\"Processing {chunksize * (count - 1)} - {chunksize * count}\")\n",
    "        relevantPaperFieldsOfStudy = relevantPaperFieldsOfStudy.append(\n",
    "            chunk[chunk.PaperId.isin(paper_list)], ignore_index=True\n",
    "        )\n",
    "        if count == num_loops:\n",
    "            break\n",
    "    relevantPaperFieldsOfStudy.to_csv(r\"results/paper_fields_of_study.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_to_file(dataframe, filepath):\n",
    "    os.remove(filepath)\n",
    "    with open(filepath, \"a\") as fd:\n",
    "        fd.write(f'{\",\".join(map(str, dataframe.columns))}')\n",
    "        for index in tqdm(range(len(dataframe))):\n",
    "            fd.write(f'\\n{\",\".join(map(str, dataframe.iloc[index]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fields_of_study_to_feature_vector(paper_fields_of_study):\n",
    "    table_dict = {}\n",
    "    for paperId in tqdm(list(set(paper_fields_of_study.PaperId))[0:10000]):\n",
    "        dataframe = paper_fields_of_study[paper_fields_of_study.PaperId == paperId]\n",
    "        table = pd.pivot_table(\n",
    "            dataframe,\n",
    "            values=\"Score\",\n",
    "            index=[\"PaperId\"],\n",
    "            columns=[\"FieldOfStudyId\"],\n",
    "            aggfunc=np.sum,\n",
    "        )\n",
    "        table_dict.update(table.T.to_dict())\n",
    "    dataframe = pd.DataFrame(table_dict).fillna(0).T.round(3)\n",
    "\n",
    "    with open(FIELDS_OF_STUDY) as fp:\n",
    "        fields_of_study_df = pd.read_csv(\n",
    "            fp, sep=\"\\t\", header=None, names=FIELDS_OF_STUDY_HEADER\n",
    "        )\n",
    "\n",
    "        level2_fields = sorted(\n",
    "            list(\n",
    "                fields_of_study_df[\n",
    "                    (fields_of_study_df.FieldOfStudyId.isin(dataframe.columns))\n",
    "                    & (fields_of_study_df.Level == 2)\n",
    "                ].FieldOfStudyId\n",
    "            )\n",
    "        )\n",
    "        dataframe = dataframe[level2_fields]\n",
    "        dataframe.columns = [\n",
    "            fields_of_study_df[fields_of_study_df.FieldOfStudyId == id]\n",
    "            .iloc[0]\n",
    "            .NormalizedName\n",
    "            for id in dataframe.columns\n",
    "        ]\n",
    "    dataframe.to_csv(r\"results/paper_features.csv\")\n",
    "    return level2_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_author_features(\n",
    "    paper_author_affiliation_for_authors, paper_fields_of_study, field_order\n",
    "):\n",
    "    dictionary = {}\n",
    "    for authorId in tqdm(set(paper_author_affiliation_for_authors.AuthorId)):\n",
    "        paperIds = list(\n",
    "            paper_author_affiliation_for_authors[\n",
    "                paper_author_affiliation_for_authors.AuthorId == authorId\n",
    "            ].PaperId\n",
    "        )\n",
    "        fields = (\n",
    "            paper_fields_of_study[paper_fields_of_study.PaperId.isin(paperIds)]\n",
    "            .filter([\"FieldOfStudyId\", \"Score\"])\n",
    "            .groupby(\"FieldOfStudyId\")\n",
    "            .mean()\n",
    "        )\n",
    "        fields_dictionary = dict(zip(fields.index, fields.Score.values))\n",
    "        dictionary[authorId] = fields_dictionary\n",
    "\n",
    "    dataframe = pd.DataFrame(dictionary).fillna(0).T.round(3)\n",
    "    dataframe = dataframe[field_order]\n",
    "    with open(FIELDS_OF_STUDY) as fp:\n",
    "        fields_of_study_df = pd.read_csv(\n",
    "            fp, sep=\"\\t\", header=None, names=FIELDS_OF_STUDY_HEADER\n",
    "        )\n",
    "\n",
    "        dataframe.columns = [\n",
    "            fields_of_study_df[fields_of_study_df.FieldOfStudyId == id]\n",
    "            .iloc[0]\n",
    "            .NormalizedName\n",
    "            for id in dataframe.columns\n",
    "        ]\n",
    "    dataframe.to_csv(r\"results/author_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_author_features_using_maximum(\n",
    "    paper_author_affiliation_for_authors, paper_fields_of_study, field_order\n",
    "):\n",
    "    dictionary = {}\n",
    "    for authorId in tqdm(set(paper_author_affiliation_for_authors.AuthorId)):\n",
    "        paperIds = list(\n",
    "            paper_author_affiliation_for_authors[\n",
    "                paper_author_affiliation_for_authors.AuthorId == authorId\n",
    "            ].PaperId\n",
    "        )\n",
    "        fields = (\n",
    "            paper_fields_of_study[paper_fields_of_study.PaperId.isin(paperIds)]\n",
    "            .filter([\"FieldOfStudyId\", \"Score\"])\n",
    "            .groupby(\"FieldOfStudyId\")\n",
    "            .max()\n",
    "        )\n",
    "        fields_dictionary = dict(zip(fields.index, fields.Score.values))\n",
    "        dictionary[authorId] = fields_dictionary\n",
    "\n",
    "    dataframe = pd.DataFrame(dictionary).fillna(0).T.round(3)\n",
    "    dataframe = dataframe[field_order]\n",
    "    with open(FIELDS_OF_STUDY) as fp:\n",
    "        fields_of_study_df = pd.read_csv(\n",
    "            fp, sep=\"\\t\", header=None, names=FIELDS_OF_STUDY_HEADER\n",
    "        )\n",
    "\n",
    "        dataframe.columns = [\n",
    "            fields_of_study_df[fields_of_study_df.FieldOfStudyId == id]\n",
    "            .iloc[0]\n",
    "            .NormalizedName\n",
    "            for id in dataframe.columns\n",
    "        ]\n",
    "    dataframe.to_csv(r\"results/author_features_max.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 - 10000000\n",
      "Processing 10000000 - 20000000\n",
      "Processing 20000000 - 30000000\n",
      "Processing 30000000 - 40000000\n",
      "Processing 40000000 - 50000000\n",
      "Processing 50000000 - 60000000\n",
      "Processing 60000000 - 70000000\n",
      "Processing 70000000 - 80000000\n",
      "Processing 80000000 - 90000000\n",
      "Processing 90000000 - 100000000\n",
      "Processing 100000000 - 110000000\n",
      "Processing 110000000 - 120000000\n",
      "Processing 120000000 - 130000000\n",
      "Processing 130000000 - 140000000\n",
      "Processing 140000000 - 150000000\n",
      "Processing 150000000 - 160000000\n",
      "Processing 160000000 - 170000000\n",
      "Processing 170000000 - 180000000\n",
      "Processing 180000000 - 190000000\n",
      "Processing 190000000 - 200000000\n",
      "Processing 200000000 - 210000000\n",
      "Processing 210000000 - 220000000\n",
      "Processing 220000000 - 230000000\n",
      "Processing 230000000 - 240000000\n",
      "Processing 240000000 - 250000000\n",
      "Processing 250000000 - 260000000\n",
      "Processing 260000000 - 270000000\n",
      "Processing 270000000 - 280000000\n",
      "Processing 280000000 - 290000000\n",
      "Processing 290000000 - 300000000\n",
      "Processing 300000000 - 310000000\n",
      "Processing 310000000 - 320000000\n",
      "Processing 320000000 - 330000000\n",
      "Processing 330000000 - 340000000\n",
      "Processing 340000000 - 350000000\n",
      "Processing 350000000 - 360000000\n",
      "Processing 360000000 - 370000000\n",
      "Processing 370000000 - 380000000\n",
      "Processing 380000000 - 390000000\n",
      "Processing 390000000 - 400000000\n",
      "Processing 400000000 - 410000000\n",
      "Processing 410000000 - 420000000\n",
      "Processing 420000000 - 430000000\n",
      "Processing 430000000 - 440000000\n",
      "Processing 440000000 - 450000000\n",
      "Processing 450000000 - 460000000\n",
      "Processing 460000000 - 470000000\n",
      "Processing 470000000 - 480000000\n",
      "Processing 480000000 - 490000000\n",
      "Processing 490000000 - 500000000\n",
      "Processing 500000000 - 510000000\n",
      "Processing 510000000 - 520000000\n",
      "Processing 520000000 - 530000000\n",
      "Processing 530000000 - 540000000\n",
      "Processing 540000000 - 550000000\n",
      "Processing 550000000 - 560000000\n",
      "Processing 560000000 - 570000000\n",
      "Processing 570000000 - 580000000\n",
      "Processing 580000000 - 590000000\n",
      "Processing 590000000 - 600000000\n",
      "Processing 600000000 - 610000000\n",
      "Processing 0 - 1000000\n",
      "Processing 1000000 - 2000000\n",
      "Processing 2000000 - 3000000\n",
      "Processing 3000000 - 4000000\n",
      "Processing 4000000 - 5000000\n",
      "Processing 5000000 - 6000000\n",
      "Processing 6000000 - 7000000\n",
      "Processing 7000000 - 8000000\n",
      "Processing 8000000 - 9000000\n",
      "Processing 9000000 - 10000000\n",
      "Processing 10000000 - 11000000\n",
      "Processing 11000000 - 12000000\n",
      "Processing 12000000 - 13000000\n",
      "Processing 13000000 - 14000000\n",
      "Processing 14000000 - 15000000\n",
      "Processing 15000000 - 16000000\n",
      "Processing 16000000 - 17000000\n",
      "Processing 17000000 - 18000000\n",
      "Processing 18000000 - 19000000\n",
      "Processing 19000000 - 20000000\n",
      "Processing 20000000 - 21000000\n",
      "Processing 21000000 - 22000000\n",
      "Processing 22000000 - 23000000\n",
      "Processing 23000000 - 24000000\n",
      "Processing 24000000 - 25000000\n",
      "Processing 25000000 - 26000000\n",
      "Processing 26000000 - 27000000\n",
      "Processing 27000000 - 28000000\n",
      "Processing 28000000 - 29000000\n",
      "Processing 29000000 - 30000000\n",
      "Processing 30000000 - 31000000\n",
      "Processing 31000000 - 32000000\n",
      "Processing 32000000 - 33000000\n",
      "Processing 33000000 - 34000000\n",
      "Processing 34000000 - 35000000\n",
      "Processing 35000000 - 36000000\n",
      "Processing 36000000 - 37000000\n",
      "Processing 37000000 - 38000000\n",
      "Processing 38000000 - 39000000\n",
      "Processing 39000000 - 40000000\n",
      "Processing 40000000 - 41000000\n",
      "Processing 41000000 - 42000000\n",
      "Processing 42000000 - 43000000\n",
      "Processing 43000000 - 44000000\n",
      "Processing 44000000 - 45000000\n",
      "Processing 45000000 - 46000000\n",
      "Processing 46000000 - 47000000\n",
      "Processing 47000000 - 48000000\n",
      "Processing 48000000 - 49000000\n",
      "Processing 49000000 - 50000000\n",
      "Processing 50000000 - 51000000\n",
      "Processing 51000000 - 52000000\n",
      "Processing 52000000 - 53000000\n",
      "Processing 53000000 - 54000000\n",
      "Processing 54000000 - 55000000\n",
      "Processing 55000000 - 56000000\n",
      "Processing 56000000 - 57000000\n",
      "Processing 57000000 - 58000000\n",
      "Processing 58000000 - 59000000\n",
      "Processing 59000000 - 60000000\n",
      "Processing 60000000 - 61000000\n",
      "Processing 61000000 - 62000000\n",
      "Processing 62000000 - 63000000\n",
      "Processing 63000000 - 64000000\n",
      "Processing 64000000 - 65000000\n",
      "Processing 65000000 - 66000000\n",
      "Processing 66000000 - 67000000\n",
      "Processing 67000000 - 68000000\n",
      "Processing 68000000 - 69000000\n",
      "Processing 69000000 - 70000000\n",
      "Processing 70000000 - 71000000\n",
      "Processing 71000000 - 72000000\n",
      "Processing 72000000 - 73000000\n",
      "Processing 73000000 - 74000000\n",
      "Processing 74000000 - 75000000\n",
      "Processing 75000000 - 76000000\n",
      "Processing 76000000 - 77000000\n",
      "Processing 77000000 - 78000000\n",
      "Processing 78000000 - 79000000\n",
      "Processing 79000000 - 80000000\n",
      "Processing 80000000 - 81000000\n",
      "Processing 81000000 - 82000000\n",
      "Processing 82000000 - 83000000\n",
      "Processing 83000000 - 84000000\n",
      "Processing 84000000 - 85000000\n",
      "Processing 85000000 - 86000000\n",
      "Processing 86000000 - 87000000\n",
      "Processing 87000000 - 88000000\n",
      "Processing 88000000 - 89000000\n",
      "Processing 89000000 - 90000000\n",
      "Processing 90000000 - 91000000\n",
      "Processing 91000000 - 92000000\n",
      "Processing 92000000 - 93000000\n",
      "Processing 93000000 - 94000000\n",
      "Processing 94000000 - 95000000\n",
      "Processing 95000000 - 96000000\n",
      "Processing 96000000 - 97000000\n",
      "Processing 97000000 - 98000000\n",
      "Processing 98000000 - 99000000\n",
      "Processing 99000000 - 100000000\n",
      "Processing 100000000 - 101000000\n",
      "Processing 101000000 - 102000000\n",
      "Processing 102000000 - 103000000\n",
      "Processing 103000000 - 104000000\n",
      "Processing 104000000 - 105000000\n",
      "Processing 105000000 - 106000000\n",
      "Processing 106000000 - 107000000\n",
      "Processing 107000000 - 108000000\n",
      "Processing 108000000 - 109000000\n",
      "Processing 109000000 - 110000000\n",
      "Processing 110000000 - 111000000\n",
      "Processing 111000000 - 112000000\n",
      "Processing 112000000 - 113000000\n",
      "Processing 113000000 - 114000000\n",
      "Processing 114000000 - 115000000\n",
      "Processing 115000000 - 116000000\n",
      "Processing 116000000 - 117000000\n",
      "Processing 117000000 - 118000000\n",
      "Processing 118000000 - 119000000\n",
      "Processing 119000000 - 120000000\n",
      "Processing 120000000 - 121000000\n",
      "Processing 121000000 - 122000000\n",
      "Processing 122000000 - 123000000\n",
      "Processing 123000000 - 124000000\n",
      "Processing 124000000 - 125000000\n",
      "Processing 125000000 - 126000000\n",
      "Processing 126000000 - 127000000\n",
      "Processing 127000000 - 128000000\n",
      "Processing 128000000 - 129000000\n",
      "Processing 129000000 - 130000000\n",
      "Processing 130000000 - 131000000\n",
      "Processing 131000000 - 132000000\n",
      "Processing 132000000 - 133000000\n",
      "Processing 133000000 - 134000000\n",
      "Processing 134000000 - 135000000\n",
      "Processing 135000000 - 136000000\n",
      "Processing 136000000 - 137000000\n",
      "Processing 137000000 - 138000000\n",
      "Processing 138000000 - 139000000\n",
      "Processing 139000000 - 140000000\n",
      "Processing 140000000 - 141000000\n",
      "Processing 141000000 - 142000000\n",
      "Processing 142000000 - 143000000\n",
      "Processing 143000000 - 144000000\n",
      "Processing 144000000 - 145000000\n",
      "Processing 145000000 - 146000000\n",
      "Processing 146000000 - 147000000\n",
      "Processing 147000000 - 148000000\n",
      "Processing 148000000 - 149000000\n",
      "Processing 149000000 - 150000000\n",
      "Processing 150000000 - 151000000\n",
      "Processing 151000000 - 152000000\n",
      "Processing 152000000 - 153000000\n",
      "Processing 153000000 - 154000000\n",
      "Processing 154000000 - 155000000\n",
      "Processing 155000000 - 156000000\n",
      "Processing 156000000 - 157000000\n",
      "Processing 157000000 - 158000000\n",
      "Processing 158000000 - 159000000\n",
      "Processing 159000000 - 160000000\n",
      "Processing 160000000 - 161000000\n",
      "Processing 161000000 - 162000000\n",
      "Processing 162000000 - 163000000\n",
      "Processing 163000000 - 164000000\n",
      "Processing 164000000 - 165000000\n",
      "Processing 165000000 - 166000000\n",
      "Processing 166000000 - 167000000\n",
      "Processing 167000000 - 168000000\n",
      "Processing 168000000 - 169000000\n",
      "Processing 169000000 - 170000000\n",
      "Processing 170000000 - 171000000\n",
      "Processing 171000000 - 172000000\n",
      "Processing 172000000 - 173000000\n",
      "Processing 173000000 - 174000000\n",
      "Processing 174000000 - 175000000\n",
      "Processing 175000000 - 176000000\n",
      "Processing 176000000 - 177000000\n",
      "Processing 177000000 - 178000000\n",
      "Processing 178000000 - 179000000\n",
      "Processing 179000000 - 180000000\n",
      "Processing 180000000 - 181000000\n",
      "Processing 181000000 - 182000000\n",
      "Processing 182000000 - 183000000\n",
      "Processing 183000000 - 184000000\n",
      "Processing 184000000 - 185000000\n",
      "Processing 185000000 - 186000000\n",
      "Processing 186000000 - 187000000\n",
      "Processing 187000000 - 188000000\n",
      "Processing 188000000 - 189000000\n",
      "Processing 189000000 - 190000000\n",
      "Processing 190000000 - 191000000\n",
      "Processing 191000000 - 192000000\n",
      "Processing 192000000 - 193000000\n",
      "Processing 193000000 - 194000000\n",
      "Processing 194000000 - 195000000\n",
      "Processing 195000000 - 196000000\n",
      "Processing 196000000 - 197000000\n",
      "Processing 197000000 - 198000000\n",
      "Processing 198000000 - 199000000\n",
      "Processing 199000000 - 200000000\n",
      "Processing 200000000 - 201000000\n",
      "Processing 201000000 - 202000000\n",
      "Processing 202000000 - 203000000\n",
      "Processing 203000000 - 204000000\n",
      "Processing 204000000 - 205000000\n",
      "Processing 205000000 - 206000000\n",
      "Processing 206000000 - 207000000\n",
      "Processing 207000000 - 208000000\n",
      "Processing 208000000 - 209000000\n",
      "Processing 209000000 - 210000000\n",
      "Processing 210000000 - 211000000\n",
      "Processing 211000000 - 212000000\n",
      "Processing 212000000 - 213000000\n",
      "Processing 213000000 - 214000000\n",
      "Processing 214000000 - 215000000\n",
      "Processing 215000000 - 216000000\n",
      "Processing 216000000 - 217000000\n",
      "Processing 217000000 - 218000000\n",
      "Processing 218000000 - 219000000\n",
      "Processing 219000000 - 220000000\n",
      "Processing 220000000 - 221000000\n",
      "Processing 221000000 - 222000000\n",
      "Processing 222000000 - 223000000\n",
      "Processing 223000000 - 224000000\n",
      "Processing 224000000 - 225000000\n",
      "Processing 225000000 - 226000000\n",
      "Processing 226000000 - 227000000\n",
      "Processing 227000000 - 228000000\n",
      "Processing 228000000 - 229000000\n",
      "Processing 229000000 - 230000000\n",
      "Processing 230000000 - 231000000\n",
      "Processing 231000000 - 232000000\n",
      "Processing 232000000 - 233000000\n",
      "Processing 0 - 10000000\n",
      "Processing 10000000 - 20000000\n",
      "Processing 20000000 - 30000000\n",
      "Processing 30000000 - 40000000\n",
      "Processing 40000000 - 50000000\n",
      "Processing 50000000 - 60000000\n",
      "Processing 60000000 - 70000000\n",
      "Processing 70000000 - 80000000\n",
      "Processing 80000000 - 90000000\n",
      "Processing 90000000 - 100000000\n",
      "Processing 100000000 - 110000000\n",
      "Processing 110000000 - 120000000\n",
      "Processing 120000000 - 130000000\n",
      "Processing 130000000 - 140000000\n",
      "Processing 140000000 - 150000000\n",
      "Processing 150000000 - 160000000\n",
      "Processing 160000000 - 170000000\n",
      "Processing 170000000 - 180000000\n",
      "Processing 180000000 - 190000000\n",
      "Processing 190000000 - 200000000\n",
      "Processing 200000000 - 210000000\n",
      "Processing 210000000 - 220000000\n",
      "Processing 220000000 - 230000000\n",
      "Processing 230000000 - 240000000\n",
      "Processing 240000000 - 250000000\n",
      "Processing 250000000 - 260000000\n",
      "Processing 260000000 - 270000000\n",
      "Processing 270000000 - 280000000\n",
      "Processing 280000000 - 290000000\n",
      "Processing 290000000 - 300000000\n",
      "Processing 300000000 - 310000000\n",
      "Processing 310000000 - 320000000\n",
      "Processing 320000000 - 330000000\n",
      "Processing 330000000 - 340000000\n",
      "Processing 340000000 - 350000000\n",
      "Processing 350000000 - 360000000\n",
      "Processing 360000000 - 370000000\n",
      "Processing 370000000 - 380000000\n",
      "Processing 380000000 - 390000000\n",
      "Processing 390000000 - 400000000\n",
      "Processing 400000000 - 410000000\n",
      "Processing 410000000 - 420000000\n",
      "Processing 420000000 - 430000000\n",
      "Processing 430000000 - 440000000\n",
      "Processing 440000000 - 450000000\n",
      "Processing 450000000 - 460000000\n",
      "Processing 460000000 - 470000000\n",
      "Processing 470000000 - 480000000\n",
      "Processing 480000000 - 490000000\n",
      "Processing 490000000 - 500000000\n",
      "Processing 500000000 - 510000000\n",
      "Processing 510000000 - 520000000\n",
      "Processing 520000000 - 530000000\n",
      "Processing 530000000 - 540000000\n",
      "Processing 540000000 - 550000000\n",
      "Processing 550000000 - 560000000\n",
      "Processing 560000000 - 570000000\n",
      "Processing 570000000 - 580000000\n",
      "Processing 580000000 - 590000000\n",
      "Processing 590000000 - 600000000\n",
      "Processing 600000000 - 610000000\n",
      "Processing 0 - 10000000\n",
      "Processing 10000000 - 20000000\n",
      "Processing 20000000 - 30000000\n",
      "Processing 30000000 - 40000000\n",
      "Processing 40000000 - 50000000\n",
      "Processing 50000000 - 60000000\n",
      "Processing 60000000 - 70000000\n",
      "Processing 70000000 - 80000000\n",
      "Processing 80000000 - 90000000\n",
      "Processing 90000000 - 100000000\n",
      "Processing 100000000 - 110000000\n",
      "Processing 110000000 - 120000000\n",
      "Processing 120000000 - 130000000\n",
      "Processing 130000000 - 140000000\n",
      "Processing 140000000 - 150000000\n",
      "Processing 150000000 - 160000000\n",
      "Processing 160000000 - 170000000\n",
      "Processing 170000000 - 180000000\n",
      "Processing 180000000 - 190000000\n",
      "Processing 190000000 - 200000000\n",
      "Processing 200000000 - 210000000\n",
      "Processing 210000000 - 220000000\n",
      "Processing 220000000 - 230000000\n",
      "Processing 230000000 - 240000000\n",
      "Processing 240000000 - 250000000\n",
      "Processing 250000000 - 260000000\n",
      "Processing 260000000 - 270000000\n",
      "Processing 270000000 - 280000000\n",
      "Processing 280000000 - 290000000\n",
      "Processing 290000000 - 300000000\n",
      "Processing 300000000 - 310000000\n",
      "Processing 310000000 - 320000000\n",
      "Processing 320000000 - 330000000\n",
      "Processing 330000000 - 340000000\n",
      "Processing 340000000 - 350000000\n",
      "Processing 350000000 - 360000000\n",
      "Processing 360000000 - 370000000\n",
      "Processing 370000000 - 380000000\n",
      "Processing 380000000 - 390000000\n",
      "Processing 390000000 - 400000000\n",
      "Processing 400000000 - 410000000\n",
      "Processing 410000000 - 420000000\n",
      "Processing 420000000 - 430000000\n",
      "Processing 430000000 - 440000000\n",
      "Processing 440000000 - 450000000\n",
      "Processing 450000000 - 460000000\n",
      "Processing 460000000 - 470000000\n",
      "Processing 470000000 - 480000000\n",
      "Processing 480000000 - 490000000\n",
      "Processing 490000000 - 500000000\n",
      "Processing 500000000 - 510000000\n",
      "Processing 510000000 - 520000000\n",
      "Processing 520000000 - 530000000\n",
      "Processing 530000000 - 540000000\n",
      "Processing 540000000 - 550000000\n",
      "Processing 550000000 - 560000000\n",
      "Processing 560000000 - 570000000\n",
      "Processing 570000000 - 580000000\n",
      "Processing 580000000 - 590000000\n",
      "Processing 590000000 - 600000000\n",
      "Processing 600000000 - 610000000\n",
      "Processing 610000000 - 620000000\n",
      "Processing 620000000 - 630000000\n",
      "Processing 630000000 - 640000000\n",
      "Processing 640000000 - 650000000\n",
      "Processing 650000000 - 660000000\n",
      "Processing 660000000 - 670000000\n",
      "Processing 670000000 - 680000000\n",
      "Processing 680000000 - 690000000\n",
      "Processing 690000000 - 700000000\n",
      "Processing 700000000 - 710000000\n",
      "Processing 710000000 - 720000000\n",
      "Processing 720000000 - 730000000\n",
      "Processing 730000000 - 740000000\n",
      "Processing 740000000 - 750000000\n",
      "Processing 750000000 - 760000000\n",
      "Processing 760000000 - 770000000\n",
      "Processing 770000000 - 780000000\n",
      "Processing 780000000 - 790000000\n",
      "Processing 790000000 - 800000000\n",
      "Processing 800000000 - 810000000\n",
      "Processing 810000000 - 820000000\n",
      "Processing 820000000 - 830000000\n",
      "Processing 830000000 - 840000000\n",
      "Processing 840000000 - 850000000\n",
      "Processing 850000000 - 860000000\n",
      "Processing 860000000 - 870000000\n",
      "Processing 870000000 - 880000000\n",
      "Processing 880000000 - 890000000\n",
      "Processing 890000000 - 900000000\n",
      "Processing 900000000 - 910000000\n",
      "Processing 910000000 - 920000000\n",
      "Processing 920000000 - 930000000\n",
      "Processing 930000000 - 940000000\n",
      "Processing 940000000 - 950000000\n",
      "Processing 950000000 - 960000000\n",
      "Processing 960000000 - 970000000\n",
      "Processing 970000000 - 980000000\n",
      "Processing 980000000 - 990000000\n",
      "Processing 990000000 - 1000000000\n",
      "Processing 1000000000 - 1010000000\n",
      "Processing 1010000000 - 1020000000\n",
      "Processing 1020000000 - 1030000000\n",
      "Processing 1030000000 - 1040000000\n",
      "Processing 1040000000 - 1050000000\n",
      "Processing 1050000000 - 1060000000\n",
      "Processing 1060000000 - 1070000000\n",
      "Processing 1070000000 - 1080000000\n",
      "Processing 1080000000 - 1090000000\n",
      "Processing 1090000000 - 1100000000\n",
      "Processing 1100000000 - 1110000000\n",
      "Processing 1110000000 - 1120000000\n",
      "Processing 1120000000 - 1130000000\n",
      "Processing 1130000000 - 1140000000\n",
      "Processing 1140000000 - 1150000000\n",
      "Processing 1150000000 - 1160000000\n",
      "Processing 1160000000 - 1170000000\n",
      "Processing 1170000000 - 1180000000\n",
      "Processing 1180000000 - 1190000000\n",
      "Processing 1190000000 - 1200000000\n",
      "Processing 1200000000 - 1210000000\n",
      "Processing 1210000000 - 1220000000\n",
      "Processing 1220000000 - 1230000000\n",
      "Processing 1230000000 - 1240000000\n",
      "Processing 1240000000 - 1250000000\n",
      "Processing 1250000000 - 1260000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/miniconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "100%|██████████| 2779/2779 [00:34<00:00, 81.41it/s]\n",
      "100%|██████████| 7152/7152 [13:58<00:00,  8.53it/s]\n",
      "100%|██████████| 7152/7152 [14:00<00:00,  8.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# This code block extract the features for simulation\n",
    "\n",
    "# extract_conferences([\n",
    "#         \"KDD 2019\",\n",
    "#         \"KDD 2018\",\n",
    "#         \"KDD 2017\",\n",
    "#         \"KDD 2016\",\n",
    "#         \"KDD 2015\",\n",
    "#         \"KDD 2014\",\n",
    "#         \"KDD 2013\",\n",
    "#         \"KDD 2012\",\n",
    "#         \"KDD 2011\",\n",
    "#         \"KDD 2010\",\n",
    "#     ], \"results/kdd_instances.csv\")\n",
    "# kdd_instances = pd.read_csv(r\"results/kdd_instances.csv\", index_col=0)\n",
    "# extract_papers(kdd_instances)\n",
    "\n",
    "kdd_papers = pd.read_csv(r\"results/kdd_papers.csv\", index_col=0)\n",
    "kdd_papers[kdd_papers.Year > 2013]\n",
    "\n",
    "extract_paper_author_affiliation(kdd_papers)\n",
    "\n",
    "kdd_paper_author_affiliation = pd.read_csv(\n",
    "    r\"results/kdd_paper_author_affiliations.csv\", index_col=0\n",
    ")\n",
    "extract_author(kdd_paper_author_affiliation)\n",
    "kdd_authors = pd.read_csv(r\"results/kdd_authors.csv\", index_col=0)\n",
    "extract_paper_author_affiliation_for_authors(kdd_authors)\n",
    "paper_author_affiliation_for_authors = pd.read_csv(\n",
    "    r\"results/kdd_paper_author_affiliations_for_authors.csv\", index_col=0\n",
    ")\n",
    "extract_paper_fields_of_study(list(paper_author_affiliation_for_authors.PaperId))\n",
    "paper_fields_of_study = pd.read_csv(r\"results/paper_fields_of_study.csv\", index_col=0)\n",
    "kdd_paper_fields_of_study = paper_fields_of_study[\n",
    "    paper_fields_of_study.PaperId.isin(kdd_papers.PaperId)\n",
    "]\n",
    "fields = convert_fields_of_study_to_feature_vector(kdd_paper_fields_of_study)\n",
    "\n",
    "paper_fields_of_study = paper_fields_of_study[\n",
    "    paper_fields_of_study.FieldOfStudyId.isin(fields)\n",
    "]\n",
    "paper_fields_of_study = pd.read_csv(r\"results/paper_fields_of_study.csv\", index_col=0)\n",
    "generate_author_features(\n",
    "    paper_author_affiliation_for_authors, paper_fields_of_study, fields\n",
    ")\n",
    "generate_author_features_using_maximum(\n",
    "    paper_author_affiliation_for_authors, paper_fields_of_study, fields\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
